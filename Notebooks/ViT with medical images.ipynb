{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "vit_dropout = 0.2\n",
    "vit_emb_dropout = 0.1\n",
    "l2_reg = 1e-3\n",
    "lr = 3e-5\n",
    "batch_size = 16\n",
    "scheduler_factor = 0.5\n",
    "scheduler_patience = 3\n",
    "scheduler_threshold = 1e-2\n",
    "max_epochs = 50\n",
    "vit_patch_size = 16\n",
    "vit_num_classes = 3\n",
    "vit_k = 128\n",
    "vit_depth = 6\n",
    "vit_heads = 8\n",
    "vit_mlp = 512\n",
    "vit_channels = 1\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lIngd4_5Q1Gk"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQdKUalNmDbu"
   },
   "source": [
    "## Definição dos diretórios:\n",
    " - base_dir: Diretório para a pasta raiz do projeto;\n",
    " - formated_dataset_dir: Diretório onde a base está armazenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r_wstTvlQ8fE"
   },
   "outputs": [],
   "source": [
    "base_dir = 'D:/CTR Pulmões - Doenças Respiratórias/CovidNet/' \n",
    "formated_dataset_dir = 'D:/CTR Pulmões - Doenças Respiratórias/CovidNet/CovidNet Formatada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gud9g46KQ-vL"
   },
   "outputs": [],
   "source": [
    "class_names = {'Normal': 0, 'Pneumonia': 1, 'Covid-19 Pneumonia': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3_ZRiHFeRAGs"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.1, 0.2),\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "val_test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rgvyJl-2t8h3"
   },
   "outputs": [],
   "source": [
    "def get_image(image_path, act,total, transform=None):\n",
    "    if(act[0]%100==0):\n",
    "        print(f\"{act[0]}/{total}\")\n",
    "    act[0]+=1\n",
    "    image = Image.open(image_path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-kTjMqIus3p"
   },
   "source": [
    "## Carregar dataset direto pra memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gcAxUUeSRjdk"
   },
   "outputs": [],
   "source": [
    "class CT_ScansDatset_memory(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        act = [1]\n",
    "        act[0] = 0\n",
    "        self.ct_scans = shuffle(pd.read_csv(csv_file, sep=' ', names=['X', 'y'], usecols=[0, 1]))\n",
    "        self.ct_scans = self.ct_scans[:len(self.ct_scans)]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        total=len(self.ct_scans)\n",
    "        self.ct_scans['X'] = self.ct_scans['X'].apply(lambda x : get_image(os.path.join(self.root_dir, x), act, total, self.transform))\n",
    "        self.ct_scans['y'] = self.ct_scans['y'].apply(lambda x : np.array(x))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ct_scans)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.ct_scans.iloc[idx, 0]\n",
    "        label = self.ct_scans.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "#         img_path = os.path.join(self.root_dir,\n",
    "#                                 self.ct_scans.iloc[idx, 0])\n",
    "#         image = Image.open(img_path)\n",
    "#         # image = image.reshape([1, 512, 512])\n",
    "#         label = self.ct_scans.iloc[idx, 1]\n",
    "#         label = np.array(label)\n",
    "        \n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7axslnIcux-M"
   },
   "source": [
    "# Carregar dataset do disco, economizando memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-JuhtbDlur3K"
   },
   "outputs": [],
   "source": [
    "class CT_ScansDatset_disk(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.ct_scans = shuffle(pd.read_csv(csv_file, sep=' ', names=['X', 'y'], usecols=[0, 1]))\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ct_scans)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_path = os.path.join(self.root_dir,\n",
    "                                self.ct_scans.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        # image = image.reshape([1, 512, 512])\n",
    "        label = self.ct_scans.iloc[idx, 1]\n",
    "        label = np.array(label)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "_dy_gsDwRlYq",
    "outputId": "7dcf1a4a-6437-4bc0-f974-97da5f99fdec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/61782\n",
      "100/61782\n",
      "200/61782\n",
      "300/61782\n",
      "400/61782\n",
      "500/61782\n",
      "600/61782\n",
      "700/61782\n",
      "800/61782\n",
      "900/61782\n",
      "1000/61782\n",
      "1100/61782\n",
      "1200/61782\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-42f9db03b9a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mct_dataset_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCT_ScansDatset_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Data Split/train_COVIDx-CT.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformated_dataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mct_dataset_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCT_ScansDatset_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Data Split/val_COVIDx-CT.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformated_dataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_test_transforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mct_dataset_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCT_ScansDatset_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Data Split/test_COVIDx-CT.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformated_dataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_test_transforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2fb6c39d441a>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, csv_file, root_dir, transform)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mget_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2fb6c39d441a>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mget_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mct_scans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-d0b70bbcc846>\u001b[0m in \u001b[0;36mget_image\u001b[1;34m(image_path, act, total, transform)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{act[0]}/{total}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mact\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ct_dataset_train = CT_ScansDatset_memory(csv_file = base_dir + 'Data Split/train_COVIDx-CT.txt', root_dir=formated_dataset_dir, transform=train_transforms)\n",
    "ct_dataset_val = CT_ScansDatset_disk(csv_file = base_dir + 'Data Split/val_COVIDx-CT.txt', root_dir=formated_dataset_dir, transform=val_test_transforms)\n",
    "ct_dataset_test = CT_ScansDatset_disk(csv_file = base_dir + 'Data Split/test_COVIDx-CT.txt', root_dir=formated_dataset_dir, transform=val_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwFZdqFdt8h8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from vit_pytorch import ViT\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAHJFjWPt8h_"
   },
   "outputs": [],
   "source": [
    "ViT_Model = ViT(\n",
    "    image_size = image_size,\n",
    "    patch_size = vit_patch_size,\n",
    "    num_classes = vit_num_classes,\n",
    "    dim = vit_k,\n",
    "    depth = vit_depth,\n",
    "    heads = vit_heads,\n",
    "    mlp_dim = vit_mlp,\n",
    "    dropout = vit_dropout,\n",
    "    emb_dropout = vit_emb_dropout,\n",
    "    channels = vit_channels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOuHXxvKt8iA"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ct_dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(ct_dataset_val, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(ct_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24s_zfK8RsI9"
   },
   "outputs": [],
   "source": [
    "class LitViT(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LitViT, self).__init__()\n",
    "        self.ViT = ViT_Model\n",
    "        self.num_classes = vit_num_classes\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.ViT(data)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        data, label = batch\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        y_hat = self(data)\n",
    "\n",
    "        loss = F.cross_entropy(y_hat, label)\n",
    "        \n",
    "        _, y_hat = torch.max(y_hat, dim=1)\n",
    "        \n",
    "        train_acc = torch.tensor(accuracy_score(y_hat.cpu(), label.cpu()))\n",
    "        \n",
    "        self.log('loss', loss)\n",
    "        \n",
    "        return {'loss':loss, 'train_acc': train_acc}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_train_acc = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
    "        \n",
    "        metrics = {'loss': avg_loss, 'accuracy': avg_train_acc}\n",
    "        self.log_parameters('training', metrics)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        data, label = batch\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        y_hat = self(data)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, label)\n",
    "        \n",
    "        a, y_hat = torch.max(y_hat, dim=1)\n",
    "        val_acc = accuracy_score(y_hat.cpu(), label.cpu())\n",
    "        val_precision = precision_score(y_hat.cpu(), label.cpu(), labels=[0, 1, 2], average=None)\n",
    "        val_recall = recall_score(y_hat.cpu(), label.cpu(), labels=[0, 1, 2], average=None)\n",
    "        try:\n",
    "            val_auc = roc_auc_score(y_hat.cpu(), label.cpu(), average=None)\n",
    "        except ValueError:\n",
    "            val_auc = 0.0\n",
    "        val_acc = torch.tensor(val_acc)\n",
    "        val_precision = torch.tensor(val_precision)\n",
    "        val_recall = torch.tensor(val_recall)\n",
    "        val_auc = torch.tensor(val_auc)\n",
    "        \n",
    "        return {'val_loss': loss, 'val_acc': val_acc, 'val_precision': val_precision, 'val_recall':val_recall, \\\n",
    "                'val_auc': val_auc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        avg_val_precision = torch.stack([x['val_precision'] for x in outputs]).mean()\n",
    "        avg_val_recall = torch.stack([x['val_recall'] for x in outputs]).mean()\n",
    "        avg_val_auc = torch.stack([x['val_auc'] for x in outputs]).mean()\n",
    "        \n",
    "        metrics = {'loss': avg_loss, 'accuracy': avg_val_acc, 'precision': avg_val_precision, \\\n",
    "                            'recall': avg_val_recall, 'auc': avg_val_auc}\n",
    "        \n",
    "        self.log_parameters('validation', metrics)\n",
    "        \n",
    "        return {'progress_bar': {'val_loss': avg_loss}}\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        data, label = batch\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        y_hat = self(data)\n",
    "        a, y_hat = torch.max(y_hat, dim=1)\n",
    "        test_acc = accuracy_score(y_hat.cpu(), label.cpu(), labels=[0, 1, 2])\n",
    "        \n",
    "        return {'test_acc': torch.tensor(test_acc)}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        avg_val_precision = torch.stack([x['val_precision'] for x in outputs]).mean()\n",
    "        avg_val_recall = torch.stack([x['val_recall'] for x in outputs]).mean()\n",
    "        avg_val_auc = torch.stack([x['val_auc'] for x in outputs]).mean()\n",
    "        \n",
    "        metrics = {'loss': avg_loss, 'accuracy': avg_val_acc, 'precision': avg_val_precision, \\\n",
    "                            'recall': avg_val_recall, 'auc': avg_val_auc}\n",
    "        progress_bar = {'loss': avg_loss}\n",
    "        \n",
    "        self.log_parameters('validation', metrics)\n",
    "        \n",
    "        return {'val_loss': avg_loss, 'progress_bar': progress_bar}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=lr, eps=1e-8, weight_decay=l2_reg)\n",
    "        return{\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience, threshold=scheduler_threshold),\n",
    "            'monitor': 'loss'\n",
    "        }\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return val_dataloader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return test_dataloader\n",
    "    \n",
    "    def log_parameters(self, group, metrics):\n",
    "        for (key, value) in metrics.items():\n",
    "            self.log(f'{group}/{key}', value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_e17q4st8iB"
   },
   "outputs": [],
   "source": [
    "# Defining Tensorboard\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"ViTNoLinformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o60-SrWMt8iB"
   },
   "outputs": [],
   "source": [
    "# Defining Checkpoints Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='loss',\n",
    "    dirpath=os.path.join(base_dir, 'checkpoints/no_linformer'),\n",
    "    filename='sample-ViT-{epoch:02d}-{val_loss:.2f}'\n",
    ")\n",
    "\n",
    "# Defining Early Stopping Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzaOXh8Nt8iB"
   },
   "outputs": [],
   "source": [
    "model = LitViT()\n",
    "model.to(device)\n",
    "trainer = pl.Trainer(gpus=1, callbacks=[checkpoint_callback, early_stopping], max_epochs=max_epochs, logger=logger)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81eDn1zWt8iB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CT Scans with ViT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
